iteration: 0 lik: -1216.4337446054192
iteration: 1 lik: -705.465092140657
iteration: 2 lik: -567.7105378749488
iteration: 3 lik: -495.0627043918733
iteration: 4 lik: -448.04404565838905
iteration: 5 lik: -414.2419543123642
iteration: 6 lik: -388.31009233232373
iteration: 7 lik: -367.5063718648545
iteration: 8 lik: -350.2591368486953
iteration: 9 lik: -335.5957761539194
iteration: 10 lik: -322.8794155687439
iteration: 11 lik: -311.6743054253331
iteration: 12 lik: -301.67151275765633
iteration: 13 lik: -292.6454198804404
iteration: 14 lik: -284.4270403932945
iteration: 15 lik: -276.8870107572922
iteration: 16 lik: -269.9243920014808
iteration: 17 lik: -263.459087872962
iteration: 18 lik: -257.4265843569292
iteration: 19 lik: -251.77421984398222
iteration: 20 lik: -246.45848884491812
iteration: 21 lik: -241.44305858548773
iteration: 22 lik: -236.69728681233767
iteration: 23 lik: -232.1950981638617
iteration: 24 lik: -227.91412114957885
iteration: 25 lik: -223.83501730620765
iteration: 26 lik: -219.9409539665489
iteration: 27 lik: -216.21718567497544
iteration: 28 lik: -212.65071873554672
iteration: 29 lik: -209.23004004440267
iteration: 30 lik: -205.94489612165287
iteration: 31 lik: -202.78611170422562
iteration: 32 lik: -199.7454397832509
iteration: 33 lik: -196.81543683488988
iteration: 34 lik: -193.98935838705344
iteration: 35 lik: -191.2610711152527
iteration: 36 lik: -188.62497846023953
iteration: 37 lik: -186.07595737344278
iteration: 38 lik: -183.6093042707652
iteration: 39 lik: -181.22068864521935
iteration: 40 lik: -178.90611307976087
iteration: 41 lik: -176.6618786318783
iteration: 42 lik: -174.48455474527356
iteration: 43 lik: -172.37095299153216
iteration: 44 lik: -170.31810406409312
iteration: 45 lik: -168.3232375440146
iteration: 46 lik: -166.38376403644665
iteration: 47 lik: -164.49725934218114
iteration: 48 lik: -162.66145038249863
iteration: 49 lik: -160.87420264021853
iteration: 50 lik: -159.13350891692707
iteration: 51 lik: -157.43747923717055
iteration: 52 lik: -155.78433175607017
iteration: 53 lik: -154.1723845482131
iteration: 54 lik: -152.60004817356142
iteration: 55 lik: -151.06581893103063
iteration: 56 lik: -149.5682727228758
iteration: 57 lik: -148.10605946351674
iteration: 58 lik: -146.67789797519043
iteration: 59 lik: -145.28257132024208
iteration: 60 lik: -143.91892252609503
iteration: 61 lik: -142.58585066423527
iteration: 62 lik: -141.28230724906567
iteration: 63 lik: -140.0072929263128
iteration: 64 lik: -138.75985442400335
iteration: 65 lik: -137.539081741887
iteration: 66 lik: -136.34410555766272
iteration: 67 lik: -135.17409483056946
iteration: 68 lik: -134.02825458480262
iteration: 69 lik: -132.90582385693236
iteration: 70 lik: -131.8060737930068
iteration: 71 lik: -130.72830588237898
iteration: 72 lik: -129.67185031651164
iteration: 73 lik: -128.63606446210798
iteration: 74 lik: -127.62033143890724
iteration: 75 lik: -126.62405879337378
iteration: 76 lik: -125.64667726032465
iteration: 77 lik: -124.68763960526802
iteration: 78 lik: -123.74641954090194
iteration: 79 lik: -122.82251071181729
iteration: 80 lik: -121.91542574200179
iteration: 81 lik: -121.02469534024206
iteration: 82 lik: -120.14986745896293
iteration: 83 lik: -119.29050650245564
iteration: 84 lik: -118.44619258081467
iteration: 85 lik: -117.61652080623031
iteration: 86 lik: -116.8011006285905
iteration: 87 lik: -115.99955520760899
iteration: 88 lik: -115.21152081894587
iteration: 89 lik: -114.43664629199849
iteration: 90 lik: -113.67459247724814
iteration: 91 lik: -112.92503174122388
iteration: 92 lik: -112.18764748728485
iteration: 93 lik: -111.46213370060867
iteration: 94 lik: -110.74819451585412
iteration: 95 lik: -110.04554380612917
iteration: 96 lik: -109.35390479196631
iteration: 97 lik: -108.67300966912543
iteration: 98 lik: -108.00259925412459
iteration: 99 lik: -107.3424226464757
iteration: 100 lik: -106.69223690667523
iteration: 101 lik: -106.05180674907677
iteration: 102 lik: -105.4209042488074
iteration: 103 lik: -104.79930856197791
iteration: 104 lik: -104.18680565845408
iteration: 105 lik: -103.58318806653313
iteration: 106 lik: -102.98825462888497
iteration: 107 lik: -102.40181026917895
iteration: 108 lik: -101.82366576883906
iteration: 109 lik: -101.25363755341299
iteration: 110 lik: -100.6915474880657
iteration: 111 lik: -100.13722268174591
iteration: 112 lik: -99.5904952995831
iteration: 113 lik: -99.05120238312206
iteration: 114 lik: -98.51918567800993
iteration: 115 lik: -97.99429146877056
iteration: 116 lik: -97.47637042033226
iteration: 117 lik: -96.96527742598589
iteration: 118 lik: -96.46087146147369
iteration: 119 lik: -95.9630154449224
iteration: 120 lik: -95.47157610234201
iteration: 121 lik: -94.98642383845319
iteration: 122 lik: -94.50743261258172
iteration: 123 lik: -94.0344798194042
iteration: 124 lik: -93.56744617432312
iteration: 125 lik: -93.10621560326705
iteration: 126 lik: -92.6506751367206
iteration: 127 lik: -92.20071480779885
iteration: 128 lik: -91.75622755419528
iteration: 129 lik: -91.3171091238251
iteration: 130 lik: -90.88325798402353
iteration: 131 lik: -90.45457523412976
iteration: 132 lik: -90.03096452132687
iteration: 133 lik: -89.6123319595949
iteration: 134 lik: -89.1985860516499
iteration: 135 lik: -88.78963761374621
iteration: 136 lik: -88.38539970321483
iteration: 137 lik: -87.98578754864623
iteration: 138 lik: -87.59071848258625
iteration: 139 lik: -87.2001118766589
iteration: 140 lik: -86.81388907901648
iteration: 141 lik: -86.43197335401503
iteration: 142 lik: -86.05428982403804
iteration: 143 lik: -85.68076541337356
iteration: 144 lik: -85.31132879406984
iteration: 145 lik: -84.94591033368825
iteration: 146 lik: -84.58444204488089
iteration: 147 lik: -84.22685753671851
iteration: 148 lik: -83.87309196770562
iteration: 149 lik: -83.52308200041219
iteration: 150 lik: -83.17676575766524
iteration: 151 lik: -82.83408278023262
iteration: 152 lik: -82.49497398594953
iteration: 153 lik: -82.15938163022835
iteration: 154 lik: -81.82724926789756
iteration: 155 lik: -81.4985217163266
iteration: 156 lik: -81.17314501977852
iteration: 157 lik: -80.85106641494951
iteration: 158 lik: -80.53223429765131
iteration: 159 lik: -80.21659819059077
iteration: 160 lik: -79.90410871220816
iteration: 161 lik: -79.59471754653082
iteration: 162 lik: -79.2883774140106
iteration: 163 lik: -78.9850420433018
iteration: 164 lik: -78.68466614395237
iteration: 165 lik: -78.3872053799664
iteration: 166 lik: -78.09261634421179
iteration: 167 lik: -77.80085653364334
iteration: 168 lik: -77.51188432530775
iteration: 169 lik: -77.22565895309701
iteration: 170 lik: -76.942140485243
iteration: 171 lik: -76.6612898025004
iteration: 172 lik: -76.3830685770117
iteration: 173 lik: -76.10743925182616
iteration: 174 lik: -75.83436502104291
iteration: 175 lik: -75.5638098105636
iteration: 176 lik: -75.29573825943017
iteration: 177 lik: -75.03011570172742
iteration: 178 lik: -74.76690814903003
iteration: 179 lik: -74.5060822733736
iteration: 180 lik: -74.24760539073777
iteration: 181 lik: -73.99144544501735
iteration: 182 lik: -73.73757099246491
iteration: 183 lik: -73.48595118659406
iteration: 184 lik: -73.23655576352343
iteration: 185 lik: -72.98935502774395
iteration: 186 lik: -72.74431983830597
iteration: 187 lik: -72.50142159539637
iteration: 188 lik: -72.26063222730752
iteration: 189 lik: -72.02192417777539
iteration: 190 lik: -71.78527039367943
iteration: 191 lik: -71.55064431308958
iteration: 192 lik: -71.31801985365246
iteration: 193 lik: -71.08737140130174
iteration: 194 lik: -70.85867379928435
iteration: 195 lik: -70.63190233749347
iteration: 196 lik: -70.40703274209675
iteration: 197 lik: -70.18404116545094
iteration: 198 lik: -69.96290417629193
iteration: 199 lik: -69.74359875019769
Norm of the learned weights = 25.55922129851249
Length of the weight vector = 1365
-----------------Printing train set performance-----------------
Accuracy=0.9977573446961202
P, R, and F1 score of the positive class=1.0 0.9829351535836177 0.9913941480206541
P, R, and F1 score of the negative class=0.9974246716456349 1.0 0.9987106756059826
Confusion Matrix
576	10
0	3873
-----------------Printing test set performance-----------------
Accuracy=0.9829596412556054
P, R, and F1 score of the positive class=0.9863013698630136 0.8944099378881988 0.9381107491856677
P, R, and F1 score of the negative class=0.9824561403508771 0.9979035639412998 0.9901196047841913
Confusion Matrix
144	17
2	952
