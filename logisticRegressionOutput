iteration: 0 lik: -1974.0108459815365
iteration: 1 lik: -1382.89996732092
iteration: 2 lik: -1176.8551824957997
iteration: 3 lik: -1057.9283008183086
iteration: 4 lik: -976.9181797818377
iteration: 5 lik: -916.5911057897883
iteration: 6 lik: -869.0656797148217
iteration: 7 lik: -830.1452246022283
iteration: 8 lik: -797.3585399226398
iteration: 9 lik: -769.1415486377688
iteration: 10 lik: -744.4486965338239
iteration: 11 lik: -722.5501749599189
iteration: 12 lik: -702.918126217983
iteration: 13 lik: -685.1590307939729
iteration: 14 lik: -668.971715680666
iteration: 15 lik: -654.1203847170598
iteration: 16 lik: -640.416833973318
iteration: 17 lik: -627.7084360754615
iteration: 18 lik: -615.8698038477456
iteration: 19 lik: -604.7968316592284
iteration: 20 lik: -594.4023056588277
iteration: 21 lik: -584.6125829864744
iteration: 22 lik: -575.3650279422961
iteration: 23 lik: -566.6060038581091
iteration: 24 lik: -558.2892842996553
iteration: 25 lik: -550.3747864575158
iteration: 26 lik: -542.8275548269509
iteration: 27 lik: -535.6169406814972
iteration: 28 lik: -528.7159355110241
iteration: 29 lik: -522.1006261134065
iteration: 30 lik: -515.7497462923392
iteration: 31 lik: -509.64430568871273
iteration: 32 lik: -503.7672805590014
iteration: 33 lik: -498.10335461170644
iteration: 34 lik: -492.6387005520975
iteration: 35 lik: -487.36079494424047
iteration: 36 lik: -482.2582605142542
iteration: 37 lik: -477.32073119464485
iteration: 38 lik: -472.5387361259207
iteration: 39 lik: -467.90359954966743
iteration: 40 lik: -463.40735409243865
iteration: 41 lik: -459.04266538769275
iteration: 42 lik: -454.80276634000745
iteration: 43 lik: -450.6813996223207
iteration: 44 lik: -446.672767228398
iteration: 45 lik: -442.77148609117154
iteration: 46 lik: -438.9725489319961
iteration: 47 lik: -435.27128963314436
iteration: 48 lik: -431.66335253173196
iteration: 49 lik: -428.14466512154667
iteration: 50 lik: -424.71141372353316
iteration: 51 lik: -421.3600217481991
iteration: 52 lik: -418.08713022635897
iteration: 53 lik: -414.88958032954827
iteration: 54 lik: -411.7643976399442
iteration: 55 lik: -408.70877796220617
iteration: 56 lik: -405.7200744976743
iteration: 57 lik: -402.79578622523155
iteration: 58 lik: -399.9335473534692
iteration: 59 lik: -397.13111772634954
iteration: 60 lik: -394.38637407944924
iteration: 61 lik: -391.69730205668225
iteration: 62 lik: -389.06198890841085
iteration: 63 lik: -386.478616801281
iteration: 64 lik: -383.9454566782865
iteration: 65 lik: -381.46086261460795
iteration: 66 lik: -379.023266620858
iteration: 67 lik: -376.6311738507425
iteration: 68 lik: -374.2831581747641
iteration: 69 lik: -371.97785808570814
iteration: 70 lik: -369.7139729052824
iteration: 71 lik: -367.49025926443437
iteration: 72 lik: -365.30552783280854
iteration: 73 lik: -363.15864027525214
iteration: 74 lik: -361.04850641561086
iteration: 75 lik: -358.9740815900916
iteration: 76 lik: -356.9343641742834
iteration: 77 lik: -354.9283932695543
iteration: 78 lik: -352.9552465360803
iteration: 79 lik: -351.0140381609862
iteration: 80 lik: -349.1039169513668
iteration: 81 lik: -347.2240645429522
iteration: 82 lik: -345.37369371612016
iteration: 83 lik: -343.55204681184335
iteration: 84 lik: -341.758394240883
iteration: 85 lik: -339.9920330801586
iteration: 86 lik: -338.2522857508246
iteration: 87 lik: -336.53849877314417
iteration: 88 lik: -334.8500415935258
iteration: 89 lik: -333.18630547963704
iteration: 90 lik: -331.5467024796869
iteration: 91 lik: -329.930664442329
iteration: 92 lik: -328.33764209379325
iteration: 93 lik: -326.7671041691156
iteration: 94 lik: -325.21853659442604
iteration: 95 lik: -323.6914417174368
iteration: 96 lik: -322.1853375833853
iteration: 97 lik: -320.699757253769
iteration: 98 lik: -319.2342481653315
iteration: 99 lik: -317.7883715268177
iteration: 100 lik: -316.361701751128
iteration: 101 lik: -314.9538259205754
iteration: 102 lik: -313.5643432830274
iteration: 103 lik: -312.1928647768269
iteration: 104 lik: -310.8390125824623
iteration: 105 lik: -309.50241969905886
iteration: 106 lik: -308.1827295438883
iteration: 107 lik: -306.8795955731444
iteration: 108 lik: -305.5926809224164
iteration: 109 lik: -304.3216580653392
iteration: 110 lik: -303.0662084890264
iteration: 111 lik: -301.8260223850305
iteration: 112 lik: -300.60079835461744
iteration: 113 lik: -299.39024312732124
iteration: 114 lik: -298.1940712917668
iteration: 115 lik: -297.01200503791193
iteration: 116 lik: -295.8437739098802
iteration: 117 lik: -294.68911456869455
iteration: 118 lik: -293.54777056424587
iteration: 119 lik: -292.4194921159444
iteration: 120 lik: -291.30403590152343
iteration: 121 lik: -290.2011648535358
iteration: 122 lik: -289.1106479631443
iteration: 123 lik: -288.03226009081385
iteration: 124 lik: -286.9657817836073
iteration: 125 lik: -285.9109990987366
iteration: 126 lik: -284.8677034331549
iteration: 127 lik: -283.83569135888894
iteration: 128 lik: -282.81476446391974
iteration: 129 lik: -281.8047291983901
iteration: 130 lik: -280.80539672593915
iteration: 131 lik: -279.8165827799954
iteration: 132 lik: -278.8381075248459
iteration: 133 lik: -277.8697954213262
iteration: 134 lik: -276.9114750969791
iteration: 135 lik: -275.9629792205286
iteration: 136 lik: -275.02414438054166
iteration: 137 lik: -274.09481096813187
iteration: 138 lik: -273.1748230635712
iteration: 139 lik: -272.2640283267074
iteration: 140 lik: -271.3622778910353
iteration: 141 lik: -270.46942626132767
iteration: 142 lik: -269.58533121469367
iteration: 143 lik: -268.70985370496913
iteration: 144 lik: -267.84285777031863
iteration: 145 lik: -266.98421044394934
iteration: 146 lik: -266.1337816678322
iteration: 147 lik: -265.2914442093376
iteration: 148 lik: -264.457073580672
iteration: 149 lik: -263.6305479610506
iteration: 150 lik: -262.8117481214795
iteration: 151 lik: -262.0005573520852
iteration: 152 lik: -261.1968613918995
iteration: 153 lik: -260.4005483610042
iteration: 154 lik: -259.6115086949685
iteration: 155 lik: -258.8296350814946
iteration: 156 lik: -258.0548223991947
iteration: 157 lik: -257.2869676584207
iteration: 158 lik: -256.52596994408833
iteration: 159 lik: -255.77173036040531
iteration: 160 lik: -255.0241519774586
iteration: 161 lik: -254.28313977956753
iteration: 162 lik: -253.5486006153742
iteration: 163 lik: -252.82044314956912
iteration: 164 lik: -252.09857781622654
iteration: 165 lik: -251.3829167736709
iteration: 166 lik: -250.67337386082775
iteration: 167 lik: -249.9698645549943
iteration: 168 lik: -249.27230593099193
iteration: 169 lik: -248.58061662163766
iteration: 170 lik: -247.89471677948632
iteration: 171 lik: -247.21452803980225
iteration: 172 lik: -246.53997348470708
iteration: 173 lik: -245.8709776084615
iteration: 174 lik: -245.2074662838487
iteration: 175 lik: -244.54936672958422
iteration: 176 lik: -243.89660747876513
iteration: 177 lik: -243.2491183482681
iteration: 178 lik: -242.60683040908754
iteration: 179 lik: -241.96967595758443
iteration: 180 lik: -241.33758848757333
iteration: 181 lik: -240.7105026632685
iteration: 182 lik: -240.08835429300487
iteration: 183 lik: -239.4710803037465
iteration: 184 lik: -238.85861871631897
iteration: 185 lik: -238.25090862135903
iteration: 186 lik: -237.6478901559552
iteration: 187 lik: -237.04950448093135
iteration: 188 lik: -236.45569375877488
iteration: 189 lik: -235.8664011321744
iteration: 190 lik: -235.2815707031373
iteration: 191 lik: -234.70114751268022
iteration: 192 lik: -234.12507752106225
iteration: 193 lik: -233.55330758853674
iteration: 194 lik: -232.98578545662536
iteration: 195 lik: -232.42245972986032
iteration: 196 lik: -231.86327985801722
iteration: 197 lik: -231.30819611878414
iteration: 198 lik: -230.7571596008829
iteration: 199 lik: -230.21012218761584
Norm of the learned weights = 35.98689149821417
Length of the weight vector = 1364
-----------------Printing train set performance-----------------
Accuracy=0.9818344920385736
P, R, and F1 score of the positive class=0.8902627511591963 0.9829351535836177 0.9343065693430657
P, R, and F1 score of the negative class=0.9973767051416579 0.9816679576555641 0.9894599869876382
Confusion Matrix
576	10
71	3802
-----------------Printing test set performance-----------------
Accuracy=0.9560538116591928
P, R, and F1 score of the positive class=0.8111111111111111 0.906832298136646 0.8563049853372435
P, R, and F1 score of the negative class=0.983957219251337 0.9643605870020965 0.9740603493912123
Confusion Matrix
146	15
34	920
